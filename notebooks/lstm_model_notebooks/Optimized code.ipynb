{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a044f3e9-754a-4a66-aebd-901f14492d74",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdcdd16-1f9d-45b3-9659-bdcba4e3fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import csv\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e81d60-f780-467e-8cdc-ff8125c12af3",
   "metadata": {},
   "source": [
    "#### Reading historical data from multiple files and cleaning and formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5199e8ae-c503-4193-9647-db0d25813843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dates  CPIH  CPI  Average CPIH\n",
      "0 1950-01-01   4.3  4.1           4.6\n",
      "1 1950-02-01   4.3  4.1           4.6\n",
      "2 1950-03-01   4.8  4.7           4.6\n",
      "3 1950-04-01   5.4  5.5           4.6\n",
      "4 1950-05-01   3.7  3.7           4.6\n",
      "        Year  Change in %\n",
      "0 1949-01-01          3.3\n",
      "1 1950-01-01          3.3\n",
      "2 1951-01-01          3.7\n",
      "3 1952-01-01          1.5\n",
      "4 1953-01-01          5.6\n"
     ]
    }
   ],
   "source": [
    "# Reading CPI CPIH data from CSV file\n",
    "cpi_monthly_1950_1988 = pd.read_csv('../input_data/cpi_data_Jan1950_Dec1988.csv')\n",
    "cpi_monthly_1989_2023 = pd.read_csv('../input_data/cpi_data_Jan1989_Oct2023.csv')\n",
    "\n",
    "#Concatinaing  both the dataframes\n",
    "cpi_data = pd.concat([cpi_monthly_1950_1988, cpi_monthly_1989_2023], axis=0)\n",
    "\n",
    "# Calculating the Average CPIH from 1950 to 2023\n",
    "avglist = cpi_data[['CPI', 'CPIH']].mean(axis=0).tolist()\n",
    "average = round(sum(avglist)/len(avglist),1)\n",
    "cpi_data['Average CPIH'] = average\n",
    "\n",
    "# Converting the 'Dates' column in the cpi_data DataFrame to datetime format\n",
    "cpi_data['Dates'] = pd.to_datetime(cpi_data['Dates'])\n",
    "print(cpi_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1309c90c-f34e-4e2c-8d8a-21df94d87d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Year  Change in %\n",
      "0 1949-01-01          3.3\n",
      "1 1950-01-01          3.3\n",
      "     Dates  GDP Change in %\n",
      "0  1955 Q2              0.0\n",
      "1  1955 Q3              2.0\n",
      "        Dates  GDP Change in %\n",
      "0  1955-04-01              0.0\n",
      "1  1955-07-01              2.0\n"
     ]
    }
   ],
   "source": [
    "# Reading GDP data from CSV file\n",
    "gdp_yearly_1949_2022 =  pd.read_csv('../input_data/gdp_yearly_1949_2022.csv')\n",
    "gdp_quarterly_1955_2023 =  pd.read_csv('../input_data/gdp_quarterly_1955_2023.csv')\n",
    "\n",
    "# Transforming 'Year' column in gdp_yearly_1949_2022 to datetime format\n",
    "gdp_yearly_1949_2022['Month'] = '-01-01'\n",
    "gdp_yearly_1949_2022['Year'] = gdp_yearly_1949_2022['Year'].astype('str')+gdp_yearly_1949_2022['Month'].astype('str')\n",
    "gdp_yearly_1949_2022 = gdp_yearly_1949_2022.drop(columns=['Month'])\n",
    "gdp_yearly_1949_2022['Year'] = pd.to_datetime(gdp_yearly_1949_2022['Year'])\n",
    "print(gdp_yearly_1949_2022.head())\n",
    "\n",
    "print(gdp_quarterly_1955_2023.head())\n",
    "# Convert 'Dates' column to \"YYYY-MM-DD\" format\n",
    "def convert_to_date(quarter_year):\n",
    "    year, quarter = quarter_year.split()\n",
    "    month = (int(quarter[1:]) - 1) * 3 + 1  # Convert quarter to month\n",
    "    return f'{year}-{month:02d}-01'\n",
    "\n",
    "gdp_quarterly_1955_2023['Dates'] = gdp_quarterly_1955_2023['Dates'].apply(convert_to_date)\n",
    "print(gdp_quarterly_1955_2023.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bd5f01-b2fe-4d75-b760-9249cb3e27c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Function to transform a time series sequence into a supervised learning problem with input-output pairs (X, y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a0f829-334a-4363-8e47-6b26846e27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence) - (n_steps_in + n_steps_out)):\n",
    "        append_X = []\n",
    "        append_y = []\n",
    "        for j in range(n_steps_in):\n",
    "            append_X.append(sequence[i + j])\n",
    "        for k in range(n_steps_out):\n",
    "            append_y.append(sequence[i + n_steps_in + k + 1])\n",
    "\n",
    "        X.append(append_X)\n",
    "        y.append(append_y)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cbf5c-869f-444c-bad0-4ce03625db68",
   "metadata": {},
   "source": [
    "#### Function to prepare and scale time series data, create sequences, and split data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd4bd4f-2197-4fc6-adb0-d98cf75c1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_inflation(df, target_column, n_steps_in, n_steps_out):\n",
    "    # Scale data between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = asarray(df[target_column]).reshape(-1, 1)\n",
    "    scaled_data = scaler.fit_transform(scaled_data)\n",
    "    # Omit the last 50 observations for out-of-sample forecast\n",
    "    out_of_sample_input = scaled_data[len(scaled_data) - 50 :, 0]\n",
    "    scaled_data = scaled_data[: len(scaled_data) - 50, 0]\n",
    "\n",
    "\n",
    "    # Create sequences for input (X) and output (y)\n",
    "    X, y = split_sequences(scaled_data, n_steps_in, n_steps_out)\n",
    "\n",
    "\n",
    "    # Split data into training and testing 80:20\n",
    "    total_rows = X.shape[0]\n",
    "    train_rows = int(total_rows * 0.8)\n",
    "    test_rows = total_rows - train_rows\n",
    "\n",
    "\n",
    "    # Obtain training and testing data\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    y_train = y[:train_rows]\n",
    "    y_test = y[train_rows:]\n",
    "\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "\n",
    "    # Build and train the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(75, activation=\"relu\", return_sequences=True, input_shape=(n_steps_in, 1))\n",
    "    )\n",
    "    model.add(LSTM(75, activation=\"relu\", return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    training_model = model.fit(X_train, y_train, epochs=50, verbose=1)\n",
    "\n",
    "\n",
    "    # Perform out-of-sample forecast\n",
    "    out_of_sample_input = asarray(out_of_sample_input).reshape(1, n_steps_in)\n",
    "    out_of_sample_forecast = model.predict(out_of_sample_input, verbose=0)\n",
    "\n",
    "\n",
    "    # Inversely scale the forecasted data\n",
    "    list_forecast = scaler.inverse_transform(out_of_sample_forecast).tolist()\n",
    "    print(\n",
    "        f\"Predicted {target_column} Data for next {n_steps_out} months: \",\n",
    "        list_forecast[0],\n",
    "    )\n",
    "    return list_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26171c66-f3c2-4346-b96c-9dfc91e2e9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Greenwich\\uk_inflation_prediction\\.venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Greenwich\\uk_inflation_prediction\\.venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From D:\\Greenwich\\uk_inflation_prediction\\.venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "20/20 [==============================] - 5s 84ms/step - loss: 0.0589\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0214\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0171\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0164\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0158\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0138\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0141\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0131\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0121\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0123\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0115\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0120\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0115\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0111\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0114\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0105\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0097\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0097\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0099\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0101\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0089\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0099\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0115\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0113\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0105\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0100\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0095\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0101\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0098\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0091\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0097\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0095\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0093\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0088\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0090\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0086\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0088\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.0089\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 70ms/step - loss: 0.0081\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 46ms/step - loss: 0.0081\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0079\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.0082\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.0083\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0081\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0081\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.0078\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.0072\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 0.0076\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0070\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0065\n",
      "Predicted CPI Data for next 12 months:  [5.225424766540527, 5.515841484069824, 5.7257208824157715, 6.0762224197387695, 6.544962406158447, 6.714224815368652, 6.345033645629883, 6.6541595458984375, 7.222318172454834, 7.137748718261719, 7.388071060180664, 7.018944263458252]\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 8s 87ms/step - loss: 0.0713\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0264\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0186\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0177\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0159\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 2s 75ms/step - loss: 0.0155\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 2s 75ms/step - loss: 0.0136\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0145\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 75ms/step - loss: 0.0131\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0137\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0123\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0123\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0123\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0125\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0121\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0118\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0112\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0109\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 1s 69ms/step - loss: 0.0107\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 1s 67ms/step - loss: 0.0100\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.0104\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 1s 68ms/step - loss: 0.0103\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0100\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0103\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0109\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0099\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0094\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0088\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0093\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0087\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0089\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0094\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0098\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0102\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0088\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0075\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0078\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0076\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 1s 72ms/step - loss: 0.0080\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0079\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0077\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0075\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0068\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0068\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 1s 74ms/step - loss: 0.0071\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 1s 73ms/step - loss: 0.0090\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0079\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0076\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0065\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0060\n",
      "Predicted CPIH Data for next 12 months:  [5.289930820465088, 5.113250255584717, 5.069354057312012, 5.321040153503418, 5.237077236175537, 5.09964656829834, 5.087471008300781, 5.174588680267334, 5.33500862121582, 5.225862503051758, 5.243036270141602, 5.029095649719238]\n"
     ]
    }
   ],
   "source": [
    "input_df = cpi_data.copy()\n",
    "input_df.set_index(\"Dates\", inplace=True)\n",
    "\n",
    "\n",
    "# Predict CPI for the next 12 months\n",
    "cpi_predicted_list = predict_inflation(input_df, \"CPI\", 50, 12)\n",
    "\n",
    "\n",
    "# Predict CPIH for the next 12 months\n",
    "cpih_predicted_list = predict_inflation(input_df, \"CPIH\", 50, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ed680-167a-4c3c-9405-c2aaece28f52",
   "metadata": {},
   "source": [
    "#### Calculate and print error metrics for CPI and CPIH predictions based on the last forecasted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e20578-3251-4c93-83df-ceb1a57bce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPI Errors: MSE = 10.251372543195584, RMSE = 3.201776466775216, MAE = 2.6887910207112626\n",
      "CPIH Errors: MSE = 8.199690470644937, RMSE = 2.863510165975483, MAE = 2.5444024562835694\n"
     ]
    }
   ],
   "source": [
    "# Calculate errors for CPI\n",
    "mse_cpi = mean_squared_error(cpi_data[\"CPI\"].tolist()[-len(cpi_predicted_list[0]):], cpi_predicted_list[0])\n",
    "rmse_cpi = math.sqrt(mse_cpi)\n",
    "mae_cpi = mean_absolute_error(cpi_data[\"CPI\"].tolist()[-len(cpi_predicted_list[0]):], cpi_predicted_list[0])\n",
    "\n",
    "\n",
    "# Calculate errors for CPIH\n",
    "mse_cpih = mean_squared_error(cpi_data[\"CPIH\"].tolist()[-len(cpih_predicted_list[0]):], cpih_predicted_list[0])\n",
    "rmse_cpih = math.sqrt(mse_cpih)\n",
    "mae_cpih = mean_absolute_error(cpi_data[\"CPIH\"].tolist()[-len(cpih_predicted_list[0]):], cpih_predicted_list[0])\n",
    "\n",
    "\n",
    "# Print the calculated error metrics\n",
    "print(f\"CPI Errors: MSE = {mse_cpi}, RMSE = {rmse_cpi}, MAE = {mae_cpi}\")\n",
    "print(f\"CPIH Errors: MSE = {mse_cpih}, RMSE = {rmse_cpih}, MAE = {mae_cpih}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc20a0c-9cc0-4699-8053-6254b47f211c",
   "metadata": {},
   "source": [
    "#### Creating CSV file of Actual Historical CPI and CPIH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "111c4a52-6bef-4d87-94ab-f3c7eb1b2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>CPIH</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Average CPIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2023-06-01</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2023-07-01</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dates  CPIH  CPI  Average CPIH\n",
       "413  2023-06-01   7.3  7.9           4.6\n",
       "414  2023-07-01   6.4  6.8           4.6\n",
       "415  2023-08-01   6.3  6.7           4.6\n",
       "416  2023-09-01   6.3  6.7           4.6\n",
       "417  2023-10-01   4.7  4.6           4.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formating Dates column data.\n",
    "cpi_data['Dates'] = pd.to_datetime(cpi_data['Dates']).dt.strftime('%Y-%m-%d')\n",
    "# Saving historical data in output folder\n",
    "cpi_data.to_excel('../output_data/CPI_CPIH_Inflation_Historical_data.xlsx', index=False)\n",
    "cpi_data.head()\n",
    "cpi_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cf2d0f5-f033-4294-ac88-b9dda9bacce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPIH</th>\n",
       "      <th>Average CPIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>5.52</td>\n",
       "      <td>5.11</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>5.73</td>\n",
       "      <td>5.07</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>6.08</td>\n",
       "      <td>5.32</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>6.54</td>\n",
       "      <td>5.24</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates   CPI  CPIH  Average CPIH\n",
       "0 2023-11-01  5.23  5.29           4.6\n",
       "1 2023-12-01  5.52  5.11           4.6\n",
       "2 2024-01-01  5.73  5.07           4.6\n",
       "3 2024-02-01  6.08  5.32           4.6\n",
       "4 2024-03-01  6.54  5.24           4.6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'prediction_start_date' is the base date, starting from November 2023\n",
    "prediction_start_date = datetime.strptime('11/2023', '%m/%Y')\n",
    "# Specified the 12 number becuase we want months future months list\n",
    "month = 12\n",
    "# Create the list of datetime objects\n",
    "future_date_list = [prediction_start_date + relativedelta(months=i) for i in range(month)]\n",
    "# Creating Final Dataframe of predicted CPI and CPIH data\n",
    "prediction_df = pd.DataFrame({'Dates':future_date_list, 'CPI':cpi_predicted_list[0], 'CPIH':cpih_predicted_list[0]})\n",
    "prediction_df['Average CPIH'] = average\n",
    "prediction_df[['CPI', 'CPIH', 'Average CPIH']] = prediction_df[['CPI', 'CPIH', 'Average CPIH']].round(2)\n",
    "prediction_df.to_excel('../output_data/CPI_CPIH_Inflation_Over_Next_12_Months.xlsx', index=False)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9efe3c-d9bf-41d5-99c5-8f5e4d238bde",
   "metadata": {},
   "source": [
    "#### Implementation for GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f46b49-9826-4526-b8bf-1a625cbe10ce",
   "metadata": {},
   "source": [
    "##### existing code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c20fdf7-0fc9-46c6-98af-f1cf8c5edc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Bulding a model for GDP Growth using LSTM time varient approach and training the model on historical data\n",
    "def predict_gdp_growth(gdp_data, target_column, n_steps_in, n_steps_out):\n",
    "    # Scale data between -1 and 1\n",
    "    gdp_scaler = MinMaxScaler()\n",
    "    scaled_gdp = asarray(gdp_data[target_column]).reshape(-1, 1)\n",
    "    scaled_gdp = gdp_scaler.fit_transform(scaled_gdp)\n",
    "    # Omit the last 50 observations for out-of-sample forecast\n",
    "    gdp_sample_forecast_input = scaled_gdp[len(scaled_gdp) - n_steps_in:, 0]\n",
    "    scaled_gdp = scaled_gdp[:, 0]\n",
    "\n",
    "    # Set the number of lags and forecast periods\n",
    "    # n_steps_in = 10\n",
    "    # n_steps_out = 5\n",
    "    \n",
    "    # Create sequences for input (X) and output (y)\n",
    "    X, y = split_sequences(scaled_gdp, n_steps_in, n_steps_out)\n",
    "    \n",
    "    # Split data into training and testing 80:20\n",
    "    total_rows = X.shape[0]\n",
    "    train_rows = int(total_rows * 0.8)\n",
    "    test_rows = total_rows - train_rows\n",
    "    \n",
    "    # Obtain training and testing data\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    y_train = y[:train_rows]\n",
    "    y_test = y[train_rows:]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "    \n",
    "    # Build and train the LSTM model\n",
    "    \n",
    "    # Initialize a sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add the first LSTM layer with 75 units, ReLU activation, and input shape (n_steps_in, 1)\n",
    "    # Return sequences as there is another LSTM layer following\n",
    "    model.add(LSTM(75, activation='relu', input_shape=(n_steps_in, 1)))\n",
    "    \n",
    "    # Add a dropout layer with a dropout rate of 0.2 to prevent overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Add a dense (fully connected) layer with n_steps_out units for prediction\n",
    "    model.add(Dense(n_steps_out))\n",
    "    \n",
    "    # Compile the model with mean squared error loss and the Adam optimizer\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    training_model = model.fit(X_train, y_train, epochs=50, verbose=1)\n",
    "    \n",
    "    # Perform out-of-sample forecast\n",
    "    gdp_sample_forecast_input = asarray(gdp_sample_forecast_input).reshape(1, n_steps_in)\n",
    "    dpg_sample_forecast = model.predict(gdp_sample_forecast_input, verbose=0)\n",
    "    \n",
    "    # Inversely scale the forecasted data and save it to a CSV file\n",
    "    gdp_list_forecast = gdp_scaler.inverse_transform(dpg_sample_forecast).tolist()\n",
    "    # print('Predicted GDP Growth for next 10 Years: ', gdp_list_forecast[0])\n",
    "    return gdp_list_forecast[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cf0c644-9ef0-4c5a-a90d-3a848646dcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 2s 38ms/step - loss: 0.4569\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4312\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4033\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3741\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3432\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3151\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.2844\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2661\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2259\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1989\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1795\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1308\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1034\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0946\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0976\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0946\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0840\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0848\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0740\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0706\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0696\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0667\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0710\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0640\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0610\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0558\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0634\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0593\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0564\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0547\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0629\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0581\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0574\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0661\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0504\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0515\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0477\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0565\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0574\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0607\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0524\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0519\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0521\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0539\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0436\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0465\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0604\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0487\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0515\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0475\n"
     ]
    }
   ],
   "source": [
    "# Setting idex as Dates column\n",
    "gdp_input_df = gdp_yearly_1949_2022.copy()\n",
    "gdp_input_df.set_index('Year', inplace=True)\n",
    "gdp_predicted_list = predict_gdp_growth(gdp_input_df, 'Change in %', 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90ca4f6a-33c3-4c8e-9286-169273e4902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 2s 31ms/step - loss: 0.3058\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.2630\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.2158\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1386\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0915\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0762\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0622\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0518\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0476\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0423\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0366\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.0345\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0350\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0321\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0294\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0323\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0283\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0275\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0253\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0253\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0205\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0241\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0240\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0237\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0221\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0207\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0186\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0197\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 50ms/step - loss: 0.0193\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0194\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0188\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0188\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.0177\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 0.0182\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0179\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0167\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 42ms/step - loss: 0.0155\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0161\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0154\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0154\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0159\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0144\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0148\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0148\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0123\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0137\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0132\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0121\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0129\n"
     ]
    }
   ],
   "source": [
    "gdp_quarterly_input_df = gdp_quarterly_1955_2023.copy()\n",
    "gdp_quarterly_input_df.set_index('Dates', inplace=True)\n",
    "gdp_quarterly_predicted_list = predict_gdp_growth(gdp_quarterly_input_df, 'GDP Change in %', 50, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "587dc6d3-8881-41eb-98bc-4b8a2d50fffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>-0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>-0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-04-01</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>-0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-10-01</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2026-04-01</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2026-07-01</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Year  GDP Change in %\n",
       "0  2023-10-01            -0.12\n",
       "1  2024-01-01             0.20\n",
       "2  2024-04-01            -0.39\n",
       "3  2024-07-01             0.35\n",
       "4  2024-10-01            -0.30\n",
       "5  2025-01-01             0.08\n",
       "6  2025-04-01             0.18\n",
       "7  2025-07-01            -0.34\n",
       "8  2025-10-01             0.26\n",
       "9  2026-01-01             0.16\n",
       "10 2026-04-01            -0.05\n",
       "11 2026-07-01             0.23"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Historic data\n",
    "gdp_quarterly_1955_2023.to_excel('../output_data/GDP_Growth_Historical_Querterly_data.xlsx', index=False)\n",
    "print(gdp_quarterly_1955_2023.head())\n",
    "\n",
    "# Generate a list of the next 5 years\n",
    "quarters = 12\n",
    "# Querts should be 01/XXXX, 04/XXXX, 07/XXXX, 10/XXXX months\n",
    "gdp_growth_start_quarter = datetime.strptime('10/2023', '%m/%Y')\n",
    "next_12_quarters = [gdp_growth_start_quarter + relativedelta(months=3 * i) for i in range(quarters)]\n",
    "predicted_querterly_gdp_growth = pd.DataFrame({'Year':next_12_quarters, 'GDP Change in %':gdp_quarterly_predicted_list})\n",
    "predicted_querterly_gdp_growth['GDP Change in %'] = predicted_querterly_gdp_growth['GDP Change in %'].round(2)\n",
    "predicted_querterly_gdp_growth.to_excel('../output_data/GDP_Growth_Over_next_12_Querters.xlsx', index=False)\n",
    "print(predicted_querterly_gdp_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86b7cf39-5764-485b-aa13-4fac2c65d28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-01</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2027-01-01</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Change in %\n",
       "0 2023-01-01         0.67\n",
       "1 2024-01-01         0.97\n",
       "2 2025-01-01         0.05\n",
       "3 2026-01-01         0.76\n",
       "4 2027-01-01         0.45"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Historic data\n",
    "gdp_yearly_1949_2022.to_excel('../output_data/GDP_Growth_Historical_data.xlsx', index=False)\n",
    "print(gdp_yearly_1949_2022.head())\n",
    "\n",
    "# Generate a list of the next 5 years\n",
    "years = 5\n",
    "gdp_growth_start_year = datetime.strptime('01/2023', '%m/%Y')\n",
    "next_5_years = [gdp_growth_start_year + relativedelta(years=i) for i in range(years)]\n",
    "predicted_gdp_growth = pd.DataFrame({'Year':next_5_years, 'Change in %':gdp_predicted_list})\n",
    "predicted_gdp_growth['Change in %'] = predicted_gdp_growth['Change in %'].round(2)\n",
    "predicted_gdp_growth.to_excel('../output_data/GDP_Growth_Over_next_5_Years.xlsx', index=False)\n",
    "print(predicted_gdp_growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77b97b23-9f80-488d-b662-5a6b26167de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_time_series(df, n_steps_in, n_steps_out, target_column=None):\n",
    "    # Scale data between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # If target_column is specified, use it; otherwise, use the first column\n",
    "    target_column = target_column or df.columns[0]\n",
    "    \n",
    "    scaled_data = asarray(df[target_column]).reshape(-1, 1)\n",
    "    scaled_data = scaler.fit_transform(scaled_data)\n",
    "    \n",
    "    # Omit the last 50 observations for out-of-sample forecast\n",
    "    out_of_sample_input = scaled_data[len(scaled_data) - 50 :, 0]\n",
    "    scaled_data = scaled_data[: len(scaled_data) - 50, 0]\n",
    "\n",
    "    # Create sequences for input (X) and output (y)\n",
    "    X, y = split_sequences(scaled_data, n_steps_in, n_steps_out)\n",
    "\n",
    "    # Split data into training and testing 80:20\n",
    "    total_rows = X.shape[0]\n",
    "    train_rows = int(total_rows * 0.8)\n",
    "    test_rows = total_rows - train_rows\n",
    "\n",
    "    # Obtain training and testing data\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    y_train = y[:train_rows]\n",
    "    y_test = y[train_rows:]\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "\n",
    "    # Build and train the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        LSTM(75, activation=\"relu\", return_sequences=True, input_shape=(n_steps_in, 1))\n",
    "    )\n",
    "    model.add(LSTM(75, activation=\"relu\", return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    training_model = model.fit(X_train, y_train, epochs=50, verbose=1)\n",
    "\n",
    "    # Perform out-of-sample forecast\n",
    "    out_of_sample_input = asarray(out_of_sample_input).reshape(1, n_steps_in)\n",
    "    out_of_sample_forecast = model.predict(out_of_sample_input, verbose=0)\n",
    "\n",
    "    # Inversely scale the forecasted data\n",
    "    list_forecast = scaler.inverse_transform(out_of_sample_forecast).tolist()\n",
    "    print(\n",
    "        f\"Predicted {target_column} Data for next {n_steps_out} months: \",\n",
    "        list_forecast[0],\n",
    "    )\n",
    "    return list_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b27c2-b135-461d-8382-bbdb8da45b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
