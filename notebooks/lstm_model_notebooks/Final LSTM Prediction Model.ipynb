{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a2c287-58c6-43bb-b0f5-6c98ff003c4f",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3292370d-2085-47f8-ac24-9a3c63532aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from numpy import asarray\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, KFold\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import csv\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb76514-bc09-4730-937e-27d2c98a2ce5",
   "metadata": {},
   "source": [
    "#### Reading historical data from multiple files and cleaning and formatting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b222f609-54c0-42e2-9c55-22b56bfaac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Dates  CPIH  CPI  Average CPIH\n",
      "413  06/01/2023 00:00   7.3  7.9           2.6\n",
      "414  07/01/2023 00:00   6.4  6.8           2.6\n",
      "415  08/01/2023 00:00   6.3  6.7           2.6\n",
      "416  09/01/2023 00:00   6.3  6.7           2.6\n",
      "417  10/01/2023 00:00   4.7  4.6           2.6\n",
      "                Dates  Monthly GDP\n",
      "194  03/01/2023 00:00        102.3\n",
      "195  04/01/2023 00:00        102.5\n",
      "196  05/01/2023 00:00        102.3\n",
      "197  06/01/2023 00:00        103.0\n",
      "198  07/01/2023 00:00        102.4\n"
     ]
    }
   ],
   "source": [
    "# Read CPI data from CSV file\n",
    "cpi_monthly_1950_1988 = pd.read_csv('../input_data/cpi_data_Jan1950_Dec1988.csv')\n",
    "cpi_monthly_1989_2023 = pd.read_csv('../input_data/cpi_data_Jan1989_Oct2023.csv')\n",
    "gdp_2007_2023 = pd.read_csv('../input_data/gdp_data_Jan2007_Sept2023.csv')\n",
    "\n",
    "# Concat both the dataframes\n",
    "cpi_data = pd.concat([cpi_monthly_1950_1988, cpi_monthly_1989_2023], axis=0)\n",
    "cpi_data.tail()\n",
    "# Extract Year and Month from 'Dates' column from CPI data\n",
    "cpi_data['Month'] = cpi_data['Dates'].str.split('-').str[0].astype('str')\n",
    "cpi_data['Year'] = cpi_data['Dates'].str.split('-').str[1].astype('str')\n",
    "# Extract Year and Month from 'Dates' column from GDP data\n",
    "gdp_2007_2023['Month'] = gdp_2007_2023['Dates'].str.split('-').str[0].astype('str')\n",
    "gdp_2007_2023['Year'] = gdp_2007_2023['Dates'].str.split('-').str[1].astype('str')\n",
    "\n",
    "# Create a new column 'FormattedDate' in the desired format\n",
    "cpi_data['FormattedDate'] = pd.to_datetime(cpi_data['Month'] + ' ' + cpi_data['Year'], format='%b %y').dt.strftime('%m/%d/%Y %H:%M')\n",
    "cpi_data['Dates'] = cpi_data['FormattedDate']\n",
    "# Dropping temperary columns\n",
    "cpi_data = cpi_data.drop(columns=['Year', 'Month', 'FormattedDate'], axis=1)\n",
    "# Create a new column 'FormattedDate' in the desired format\n",
    "gdp_2007_2023['FormattedDate'] = pd.to_datetime(gdp_2007_2023['Month'] + ' ' + gdp_2007_2023['Year'], format='%b %y').dt.strftime('%m/%d/%Y %H:%M')\n",
    "gdp_2007_2023['Dates'] = gdp_2007_2023['FormattedDate']\n",
    "gdp_2007_2023 = gdp_2007_2023.drop(columns=['Month', 'Year', 'FormattedDate'])\n",
    "print(cpi_data.tail())\n",
    "print(gdp_2007_2023.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd535d6-2a9a-475f-8b7e-1a0458e33970",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Transform data into a univariate supervised learning problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a489330b-00c1-467a-ab1b-2190d368f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's transform our remaning data into a univariate supervised learning problem\n",
    "# Functions transforms our time series sequence into a supervised leaning problem\n",
    "# Transform data into a univariate supervised learning problem\n",
    "def split_sequences(sequence, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence) - (n_steps_in + n_steps_out)):\n",
    "        append_X = []\n",
    "        append_y = []\n",
    "        for j in range(n_steps_in):\n",
    "            append_X.append(sequence[i + j])\n",
    "        for k in range(n_steps_out):\n",
    "            append_y.append(sequence[i + n_steps_in + k + 1])\n",
    "\n",
    "        X.append(append_X)\n",
    "        y.append(append_y)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd66785-bf96-4db4-a359-9604ec48db67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bulding a model for CPI Prediction using LSTM time varient approach and training the model on historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a9c280-4534-46ef-ae00-89a95f346638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cpi_inflation(df):\n",
    "    # Scale data between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_cpi = asarray(df['CPI']).reshape(-1, 1)\n",
    "    scaled_cpi = scaler.fit_transform(scaled_cpi)\n",
    "    # Omit the last 50 observations for out-of-sample forecast\n",
    "    out_of_sample_forecast_input = scaled_cpi[len(scaled_cpi) - 50:, 0]\n",
    "    scaled_cpi = scaled_cpi[:len(scaled_cpi) - 50, 0]    \n",
    "    \n",
    "    # Set the number of lags and forecast periods\n",
    "    n_steps_in = 50\n",
    "    n_steps_out = 12\n",
    "    \n",
    "    # Create sequences for input (X) and output (y)\n",
    "    X, y = split_sequences(scaled_cpi, n_steps_in, n_steps_out)\n",
    "    \n",
    "    # Split data into training and testing 80:20\n",
    "    total_rows = X.shape[0]\n",
    "    train_rows = int(total_rows * 0.8)\n",
    "    test_rows = total_rows - train_rows\n",
    "    \n",
    "    # Obtain training and testing data\n",
    "    X_train = X[:train_rows]\n",
    "    X_test = X[train_rows:]\n",
    "    y_train = y[:train_rows]\n",
    "    y_test = y[train_rows:]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    y_train = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)\n",
    "    \n",
    "    # Build and train the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(75, activation='relu', return_sequences=True, input_shape=(n_steps_in, 1)))\n",
    "    model.add(LSTM(75, activation='relu', return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    training_model = model.fit(X_train, y_train, epochs=50, verbose=1)\n",
    "    \n",
    "    # Perform out-of-sample forecast\n",
    "    out_of_sample_forecast_input = asarray(out_of_sample_forecast_input).reshape(1, n_steps_in)\n",
    "    out_of_sample_forecast = model.predict(out_of_sample_forecast_input, verbose=0)\n",
    "    \n",
    "    # Inversely scale the forecasted data and save it to a CSV file\n",
    "    list_forecast = scaler.inverse_transform(out_of_sample_forecast).tolist()\n",
    "    print('Predicted CPI Data for next 12 months: ', list_forecast[0])\n",
    "    return list_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffbee3a-11f1-44e5-8d1c-2efc5e0d63bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Bulding a model for CPIH Prediction using LSTM time varient approach and training the model on historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29e94196-08eb-46fb-9b1a-408faa8eba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cpih_inflation(df):\n",
    "    # Scale data between 0 and 1\n",
    "    cpih_scaler = MinMaxScaler()\n",
    "    scaled_cpih = asarray(df['CPIH']).reshape(-1, 1)\n",
    "    scaled_cpih = cpih_scaler.fit_transform(scaled_cpih)\n",
    "    # Omit the last 50 observations for out-of-sample forecast\n",
    "    cpih_sample_forecast_input = scaled_cpih[len(scaled_cpih) - 50:, 0]\n",
    "    scaled_cpih = scaled_cpih[:len(scaled_cpih) - 50, 0]\n",
    "    \n",
    "    # Set the number of lags and forecast periods\n",
    "    cpih_n_steps_in = 50\n",
    "    cpih_n_steps_out = 12\n",
    "    \n",
    "    # Create sequences for input (X) and output (y)\n",
    "    X, y = split_sequences(scaled_cpih, cpih_n_steps_in, cpih_n_steps_out)\n",
    "    \n",
    "    # Split data into training and testing 80:20\n",
    "    cpih_total_rows = X.shape[0]\n",
    "    cpih_train_rows = int(cpih_total_rows * 0.8)\n",
    "    cpih_test_rows = cpih_total_rows - cpih_train_rows\n",
    "    \n",
    "    # Obtain training and testing data\n",
    "    X_train_cpih = X[:cpih_train_rows]\n",
    "    X_test_cpih = X[cpih_train_rows:]\n",
    "    y_train_cpih = y[:cpih_train_rows]\n",
    "    y_test_cpih = y[cpih_train_rows:]\n",
    "    \n",
    "    X_train_cpih = X_train_cpih.reshape(X_train_cpih.shape[0], X_train_cpih.shape[1], 1)\n",
    "    y_train_cpih = y_train_cpih.reshape(y_train_cpih.shape[0], y_train_cpih.shape[1], 1)\n",
    "    \n",
    "    # Build and train the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(75, activation='relu', return_sequences=True, input_shape=(cpih_n_steps_in, 1)))\n",
    "    model.add(LSTM(75, activation='relu', return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(cpih_n_steps_out))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    cpih_training_model = model.fit(X_train_cpih, y_train_cpih, epochs=50, verbose=1)\n",
    "    \n",
    "    # Perform out-of-sample forecast\n",
    "    cpih_sample_forecast_input = asarray(cpih_sample_forecast_input).reshape(1, cpih_n_steps_in)\n",
    "    cpih_sample_forecast = model.predict(cpih_sample_forecast_input, verbose=0)\n",
    "    \n",
    "    # Inversely scale the forecasted data and save it to a CSV file\n",
    "    cpih_list_forecast = cpih_scaler.inverse_transform(cpih_sample_forecast).tolist()\n",
    "    print('Predicted CPIH Data for next 12 months: ', cpih_list_forecast[0])\n",
    "    return cpih_list_forecast    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942f7c2-aac3-4016-9d85-56e7d5b982cd",
   "metadata": {},
   "source": [
    "#### Bulding a model for GDP Growth using LSTM time varient approach and training the model on historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4af10c-0dfa-46c5-bf9a-c508afbd8148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gdp_growth(df):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2b1d2-faef-4f30-81a1-d36e5388c65c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Calling Both CPI and CPH LSTM Models and passing input data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22249d2-79bf-4035-a7ba-ab16760f0946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 5s 83ms/step - loss: 0.0676\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0260\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0199\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0185\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0167\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0153\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 2s 89ms/step - loss: 0.0152\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0138\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0134\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0117\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0124\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0115\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0117\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0115\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0101\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0096\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0094\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0088\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0088\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.0085\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0091\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0080\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0077\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0085\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0077\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 2s 98ms/step - loss: 0.0075\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0088\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0070\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0062\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0116\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0131\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.0109\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 2s 97ms/step - loss: 0.0100\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0100\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0096\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0093\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0091\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0095\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0091\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0087\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0090\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 2s 88ms/step - loss: 0.0086\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0085\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0094\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0082\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.0086\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0080\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0080\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 2s 76ms/step - loss: 0.0078\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0068\n",
      "Predicted CPI Data for next 12 months:  [6.667708396911621, 7.10439395904541, 7.358459949493408, 7.400247573852539, 7.721502304077148, 7.6093010902404785, 7.478518486022949, 7.8217644691467285, 7.752566814422607, 7.788948059082031, 8.362661361694336, 7.834422588348389]\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 5s 85ms/step - loss: 0.0763\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0357\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0227\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 2s 99ms/step - loss: 0.0199\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0183\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0169\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 1s 75ms/step - loss: 0.0168\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 2s 77ms/step - loss: 0.0152\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0146\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0138\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0138\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0132\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0125\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0128\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 2s 105ms/step - loss: 0.0127\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0112\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 3s 124ms/step - loss: 0.0117\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0119\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0113\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0112\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 2s 104ms/step - loss: 0.0109\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0110\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0111\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 2s 100ms/step - loss: 0.0109\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0105\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 2s 82ms/step - loss: 0.0103\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0104\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 3s 132ms/step - loss: 0.0093\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 2s 95ms/step - loss: 0.0102\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 2s 96ms/step - loss: 0.0102\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0093\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 2s 93ms/step - loss: 0.0090\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0089\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0089\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0084\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 2s 80ms/step - loss: 0.0085\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 2s 92ms/step - loss: 0.0088\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0081\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 2s 90ms/step - loss: 0.0081\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 2s 87ms/step - loss: 0.0080\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 2s 85ms/step - loss: 0.0077\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0076\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0076\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 2s 94ms/step - loss: 0.0070\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 2s 83ms/step - loss: 0.0074\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 2s 84ms/step - loss: 0.0068\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 2s 78ms/step - loss: 0.0071\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 2s 81ms/step - loss: 0.0071\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 2s 86ms/step - loss: 0.0067\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 2s 79ms/step - loss: 0.0067\n",
      "Predicted CPIH Data for next 12 months:  [5.84562873840332, 5.7534379959106445, 5.878089427947998, 5.638946533203125, 5.593383312225342, 5.577181816101074, 5.781550884246826, 5.922363758087158, 5.5880513191223145, 5.659716606140137, 5.433778762817383, 5.7363128662109375]\n"
     ]
    }
   ],
   "source": [
    "# Setting idex as Dates column\n",
    "input_df = cpi_data.copy()\n",
    "input_df.set_index('Dates', inplace=True)\n",
    "cpi_predicted_list = predict_cpi_inflation(input_df)\n",
    "cpih_predicted_list = predict_cpih_inflation(input_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517db0b-6ce6-48f2-88f2-2844d9029933",
   "metadata": {},
   "source": [
    "#### Generating output data for Graphical representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13fabaa-a3e7-4445-81af-7ba7ff34732b",
   "metadata": {},
   "source": [
    "##### Creating CSV file of Predicted Output of CPI and CPIH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a65c9a-24dd-456f-bef2-44bad2a7ccdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPIH</th>\n",
       "      <th>Average CPIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>6.67</td>\n",
       "      <td>5.85</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>7.10</td>\n",
       "      <td>5.75</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>7.36</td>\n",
       "      <td>5.88</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-01</td>\n",
       "      <td>7.40</td>\n",
       "      <td>5.64</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>7.72</td>\n",
       "      <td>5.59</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dates   CPI  CPIH  Average CPIH\n",
       "0 2023-11-01  6.67  5.85           2.6\n",
       "1 2023-12-01  7.10  5.75           2.6\n",
       "2 2024-01-01  7.36  5.88           2.6\n",
       "3 2024-02-01  7.40  5.64           2.6\n",
       "4 2024-03-01  7.72  5.59           2.6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'prediction_start_date' is the base date, starting from November 2023\n",
    "prediction_start_date = datetime.strptime('11/2023', '%m/%Y')\n",
    "# Specified the 12 number becuase we want months future months list\n",
    "month = 12\n",
    "# Create the list of datetime objects\n",
    "future_date_list = [prediction_start_date + relativedelta(months=i) for i in range(month)]\n",
    "# Creating Final Dataframe of predicted CPI and CPIH data\n",
    "prediction_df = pd.DataFrame({'Dates':future_date_list, 'CPI':cpi_predicted_list[0], 'CPIH':cpih_predicted_list[0]})\n",
    "prediction_df['Average CPIH'] = 2.6 # UK Average CPIH is 2.6\n",
    "prediction_df[['CPI', 'CPIH', 'Average CPIH']] = prediction_df[['CPI', 'CPIH', 'Average CPIH']].round(2)\n",
    "prediction_df.to_csv('../output_data/CPI_Inflation_Over_Next_12_Months.csv', index=False)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc34821d-d7d6-429a-8700-9e2b9817057a",
   "metadata": {},
   "source": [
    "##### Creating CSV file of Actual Historical CPI and CPIH Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0bb16e4-f666-453f-8441-3faf62f058b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>CPIH</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Average CPIH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2050-01-01</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050-02-01</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2050-03-01</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2050-04-01</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2050-05-01</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates  CPIH  CPI  Average CPIH\n",
       "0  2050-01-01   4.3  4.1           5.8\n",
       "1  2050-02-01   4.3  4.1           5.8\n",
       "2  2050-03-01   4.8  4.7           5.8\n",
       "3  2050-04-01   5.4  5.5           5.8\n",
       "4  2050-05-01   3.7  3.7           5.8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formating Dates column data.\n",
    "cpi_data['Dates'] = pd.to_datetime(cpi_data['Dates']).dt.strftime('%Y-%m-%d')\n",
    "# Saving historical data in output folder\n",
    "cpi_data.to_csv('../output_data/CPI_Inflation_Historical_data.csv', index=False)\n",
    "cpi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb62ae-92cc-4a5b-9b7a-4e50b70199ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv('../output_data/CPI_Inflation_Over_Next_12_Months.csv', index=False)\n",
    "prediction_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
